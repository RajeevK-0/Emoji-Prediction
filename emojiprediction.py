# -*- coding: utf-8 -*-
"""EmojiPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12XWKJRRs5IEpYm4aa4A8z6AxkWRXwxCI
"""

!pip install emoji

import numpy as np
import pandas as pd
import emoji

emoji_dictionary = {"0": "\u2764\uFE0F",
                    "1": ":baseball:",
                    "2": ":beaming_face_with_smiling_eyes:",
                    "3": ":downcast_face_with_sweat:",
                    "4": ":fork_and_knife:",
                   }

emoji.emojize(":baseball:")

for label in emoji_dictionary:
    print(emoji.emojize(emoji_dictionary[label]))

train = pd.read_csv('train_emoji.csv',header=None)
test = pd.read_csv('test_emoji.csv',header=None)

train.head()

for i in range(30):
    print(train.iloc[i,0],'--->',emoji.emojize(emoji_dictionary[str(train.iloc[i,1])]))

embeddings = {}
with open('glove.6B.50d.txt',encoding='utf-8') as f:
    for line in f:
        values = line.split()
        word = values[0]
        vector = np.array(values[1:],dtype='f4')
        embeddings[word] = vector

print(embeddings['the'])

from keras.utils import to_categorical

X_train = train[0]
X_test = test[0]

y_train = to_categorical(train[1])
y_test = to_categorical(test[1])

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

def getEmbeddings(X):
    embeddingData = np.zeros((X.shape[0],10,50))
    for ix in range(X.shape[0]):
        words = X.iloc[ix].lower().split()
        for jx in range(len(words)):
            embeddingData[ix,jx,:] = embeddings[words[jx]]
    return embeddingData

emb_XT = getEmbeddings(X_train)

print(X_train[0])
# print(embeddings['never'])
# print(emb_XT[0][0])
print(emb_XT.shape)

emb_Xt = getEmbeddings(X_test)

print(emb_Xt.shape)

from keras.layers import Dense,LSTM,Dropout
from keras.models import Sequential
from keras import Input

model = Sequential()
model.add(Input(shape=(10,50)))
model.add(LSTM(32,return_sequences=True))
model.add(LSTM(16))
model.add(Dropout(0.3))
model.add(Dense(5,activation='softmax'))
model.summary()

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy'])
model.fit(emb_XT,y_train,batch_size=32,epochs=40,shuffle=True,validation_split=0.1)

model.evaluate(emb_Xt,y_test)

ypred = model.predict(emb_Xt)

for i in range(30):
    print(X_test.iloc[i])
    print(emoji.emojize(emoji_dictionary[str(np.argmax(y_test[i]))]))
    print(emoji.emojize(emoji_dictionary[str(np.argmax(ypred[i]))]))

